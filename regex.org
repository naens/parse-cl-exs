#+TITLE: Regular Expressions

* Overview

Regular expressions use a simple non-standard grammar.  It allows to
use basic unary and binary operators and sub-rules.  These regular
expressions are made to be used in grammars for scanners.  Each
expression corresponds to a rule or a subrule.  The difference between
both is that subrules are do not make an accepting state, so they can
be used as parts of rules.

* Operators

Here are the operators in order of precedence:
 * ~..~ : Range between characters.  The first or the last character
   can be missing.
 * ~*~, ~?~, ~+~: Kleene-closure, optional element, repetition
 * =~=: negation
 * ~&~, ~\~: conjunction and difference
 * ~\,\~: string concatenation
 * ~|~: union

* Rules and Subrules

Rules correspond to tokens, terminals and accepting states.  They are
defined ~<name>, '=', <regex>~.

Subrules are subexpressions that can be used by rules.  They are
defined like rules, but with a ~def~ prefix: ~\'def', <name>, '=',
<regex>~.

* Definition of the grammar of the regular expressions

#+BEGIN_SRC
def digit = 0..9
def hexdigit = 0..9 | a..f | A..F
def alpha = a..z | A..Z
def s = ' ' | 0ah | 0ad | 09h

<c> = '''', '''' | .. \ ''''
<h> = 'h' | 'H'
<hex-number> = '0x', hexdigit+ | hexdigit+, <h>
<number> = 0..9+
<name> = '<', alpha, (alpha | digit)+, '>'
<neg> = '~'
<specifier> = '*' | '?' | '+'

regex = <disjunct> (<s>*'|'<s>*, <disjunct>)*
disjunct = <term> (<s>*','<s>*, <term>)*
term = <conjunct> (<s>*('&' | '\')<s>*, <conjunct>)*
conjunct = <neg>, (<range>|<string>|<name>|'('<regex>')'), <specifier>?
range = '..', <char> | <char>, '..', <char>?
char = '''', <c>, '''' | <number> | <hex-number>
string = '''', <c>*, ''''
#+END_SRC

* Included and excluded items in the token list
Only rules are included.  For a specific character to be included, they must
have their own rule.

* Grammars for parsers
Parser also use the same grammar as regular expressions with some
differences:
 * the rules correspond to the non-terminals, the subrules are still
   possible and also defined with defs
 * the rules that are not defined but used are terminals and are supposed to
   be defined by the tokenizer
 * some operations are not possible, the only possible operations are
   concatenation, disjunction, Kleene star, repetition and option.

These grammars can be read with the same grammar reader, but are interpreted
differently and using different tools.

* Modules
Different modules are responsible for the different stages of the reading of
the files and their transformation and interpretation:
 * Grammar Reader: reads grammars for tokenizers and parsers.  Outputs
   a list of rules.
 * Dirivator: reads the regular expression rules and outputs a DFA.
 * Tokenizer: reads a file using the DFA corresponding to the grammar that
   the input file is supposed to respect, outputs a list of tokens.
 * Parser: reads the list of tokens and outputs the AST.  It can also use
   the parser grammar, depending on the implementation.
